#!/usr/bin/env python3
"""
Script para descargar modelos cuando hay conexi√≥n a internet
Ejecuta este script cuando tengas internet para preparar el modo offline
"""

import subprocess
import sys
import os
from pathlib import Path

def print_header():
    """Imprime el header del script"""
    print("=" * 60)
    print("üè¶ CORRIENTESAI - DESCARGAR MODELOS")
    print("=" * 60)
    print("Descargando modelos para funcionamiento offline...")
    print("üí° Ejecuta este script cuando tengas conexi√≥n a internet")
    print()

def check_internet():
    """Verifica si hay conexi√≥n a internet"""
    print("üåê Verificando conexi√≥n a internet...")
    try:
        import urllib.request
        urllib.request.urlopen('http://www.google.com', timeout=3)
        print("‚úÖ Conexi√≥n a internet disponible")
        return True
    except:
        print("‚ùå No hay conexi√≥n a internet")
        print("üí° Conecta a internet y vuelve a ejecutar este script")
        return False

def download_embeddings_model():
    """Descarga el modelo de embeddings"""
    print("\nüß† Descargando modelo de embeddings...")
    try:
        from sentence_transformers import SentenceTransformer
        
        print("üîÑ Descargando all-MiniLM-L6-v2...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Probar el modelo
        test_text = "Este es un texto de prueba"
        embedding = model.encode(test_text)
        
        if len(embedding) > 0:
            print("‚úÖ Modelo de embeddings descargado y funcionando")
            
            # Verificar que se guard√≥ en cach√© local
            cache_path = Path("./embeddings_cache")
            if cache_path.exists():
                print(f"‚úÖ Modelo guardado en cach√© local: {cache_path}")
            else:
                print("‚ö†Ô∏è Modelo descargado pero no se encontr√≥ en cach√© local")
            
            return True
        else:
            print("‚ùå Error con el modelo de embeddings")
            return False
    except Exception as e:
        print(f"‚ùå Error descargando modelo de embeddings: {e}")
        return False

def download_ollama_models():
    """Descarga los modelos de Ollama"""
    print("\nü§ñ Descargando modelos de Ollama...")
    
    models_to_download = [
        "mistral",  # Modelo principal
        "llama2:7b"  # Modelo de respaldo
    ]
    
    for model in models_to_download:
        print(f"üîÑ Descargando {model}...")
        try:
            result = subprocess.run(["ollama", "pull", model], 
                                  capture_output=True, text=True, timeout=600)
            if result.returncode == 0:
                print(f"‚úÖ {model} descargado correctamente")
            else:
                print(f"‚ùå Error descargando {model}: {result.stderr}")
        except subprocess.TimeoutExpired:
            print(f"‚è∞ Timeout descargando {model} (puede tardar varios minutos)")
        except Exception as e:
            print(f"‚ùå Error descargando {model}: {e}")

def create_directories():
    """Crea los directorios necesarios"""
    print("\nüìÅ Creando directorios...")
    directories = ["documents", "chroma_db", "assets", "embeddings_cache"]
    
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"‚úÖ Directorio {directory} creado/verificado")

def test_offline_functionality():
    """Prueba la funcionalidad offline"""
    print("\nüß™ Probando funcionalidad offline...")
    
    try:
        # Probar modelo de embeddings
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('all-MiniLM-L6-v2')
        embedding = model.encode("Prueba offline")
        print("‚úÖ Modelo de embeddings: OK")
        
        # Probar Ollama
        result = subprocess.run(["ollama", "list"], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ Ollama: OK")
            
            # Probar modelo Mistral
            test_result = subprocess.run(["ollama", "run", "mistral", "Hola"], 
                                       capture_output=True, text=True, timeout=30)
            if test_result.returncode == 0 and test_result.stdout.strip():
                print("‚úÖ Modelo Mistral: OK")
            else:
                print("‚ö†Ô∏è Modelo Mistral: No responde correctamente")
        else:
            print("‚ùå Ollama: No disponible")
        
        print("‚úÖ Pruebas de funcionalidad completadas")
        return True
    except Exception as e:
        print(f"‚ùå Error en pruebas: {e}")
        return False

def main():
    """Funci√≥n principal"""
    print_header()
    
    # Verificar internet
    if not check_internet():
        return False
    
    # Crear directorios
    create_directories()
    
    # Descargar modelo de embeddings
    if not download_embeddings_model():
        print("‚ùå No se pudo descargar el modelo de embeddings")
        return False
    
    # Descargar modelos de Ollama
    download_ollama_models()
    
    # Probar funcionalidad
    if test_offline_functionality():
        print("\n" + "=" * 60)
        print("üéâ ¬°DESCARGA DE MODELOS COMPLETADA!")
        print("=" * 60)
        print("‚úÖ Los modelos est√°n listos para funcionamiento offline")
        print("üöÄ Ahora puedes desconectar internet y ejecutar:")
        print("   streamlit run app.py")
        print("üí° La aplicaci√≥n funcionar√° completamente sin internet")
        print("=" * 60)
        return True
    else:
        print("\n‚ùå Descarga incompleta")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 